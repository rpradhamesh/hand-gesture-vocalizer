# hand-gesture-vocalizer
This project describes a hand gesture vocalizer system that uses Python and machine learning to convert sign language movements into spoken words. The device uses a camera to record hand movements using computer vision techniques. A deep learning model trained on a range of sign language gestures is then used to process the input data. Those with speech problems can now communicate in real-time thanks to the conversion of the identified gestures into text and speech synthesizer. This method offers a smooth, effective, and flexible way to improve accessibility, lessen the need for human translators, and improve communication between signers and non-signers
